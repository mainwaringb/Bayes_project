model{
    for(n in 1:N){
        #Generate ystar = (x0 * beta0) + (x * beta)
        #x0 is a column of 1's to get multiplied by B0 - as such, it doesn't need imputation; the easiest way to leave it out of imputation processes is to keep it separate from the matrix of X's
        ystar[n] = (x0[n] * beta0) + (inprod(x_imp[n,],beta[]))
        logit(p[n]) = ystar[n]
        y[n] ~ dbern(p[n])

        #JAGS is complaining if it encounters NAs, so fill these in with a uniform distribution
        #The values "filled in" via uniform distribution only get used for imputing other X's, as we pass estimate y using the x_hash rather than x
        x[n,1] ~ dunif(1,11)
        x[n,2] ~ dunif(1,7)

        #Impute x1: set x_imp[,1] equal to a semi-serious imputation model, with a stochastic component and deterministic component based on x2
        mu1[n] = gamma0[1] + gamma21 * x[n,2]
        randomvar[n,1] ~ dnorm(mu1[n], tau[1])
        x_imp[n,1] = missing[n,1] * randomvar[n,1] + (1 - missing[n,1]) * x[n,1]

        #Impute x2 using the same method as above
        mu2[n] = gamma0[2] + gamma12 * x[n,1]
        randomvar[n,2] ~ dnorm(mu2[n], tau[2])
        x_imp[n,2] = missing[n,2] * randomvar[n,2] + (1 - missing[n,2]) * x[n,2]


    }


    beta0 ~ dnorm(0, 0.01)
    for(i in 1:J){
        beta[i] ~ dnorm(0, 0.01)
        tau[i] ~ dgamma(0.001, 0.001)
        gamma0[i] ~ dnorm(0, .001)
    }

    #gamma01 ~ dnorm(0, .001)
    gamma21 ~ dnorm(0, .001)
    #gamma02 ~ dnorm(0, .001)
    gamma12 ~ dnorm(0, .001)

}
